{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nbasa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\nbasa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from be_great import GReaT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/merged_df_file.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_csv(df):\n",
    "\n",
    "    df = df.dropna()\n",
    "    '''for col in df.columns:\n",
    "        if pd.api.types.is_numeric_dtype(df[col]): # Handle numerical missing values (mean imputation)\n",
    "            if df[col].isnull().any():\n",
    "                df[col].fillna(df[col].mean(), inplace=True)\n",
    "        else: # Handle missing values in categorical or other object columns\n",
    "            if pd.api.types.is_object_dtype(df[col]):\n",
    "                if df[col].isnull().any():\n",
    "                    df[col].fillna(df[col].mode()[0], inplace=True)  # Impute with mode for categorical data'''\n",
    "    return df\n",
    "\n",
    "clean_data = process_csv(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = clean_data[(clean_data['numberRating'] >= 0) & (clean_data['numberRating'] <= 3)]\n",
    "clean_data = clean_data[(clean_data['numberMessageReceived'] >= 0) & (clean_data['numberMessageReceived'] <= 3)]\n",
    "clean_data = clean_data[(clean_data['numberMessageRead'] >= 0) & (clean_data['numberMessageRead'] <= 3)]\n",
    "clean_data = clean_data[(clean_data['reward'] <= 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When generating at day_part_x  = 0, columns numberRating, numberMessageReceived and numberMessageRead have a max of 1, \n",
    "# for day_part_x  = 1 the max is 2 and for day_part_x  = 2 the max is 3.\n",
    "\n",
    "def day_part_no_check(df):\n",
    "    conditions = {\n",
    "        0: {'numberRating': 1, 'numberMessageReceived': 1, 'numberMessageRead': 1},\n",
    "        1: {'numberRating': 2, 'numberMessageReceived': 2, 'numberMessageRead': 2},\n",
    "        2: {'numberRating': 3, 'numberMessageReceived': 3, 'numberMessageRead': 3}\n",
    "    }\n",
    "    \n",
    "    for day_part, max_values in conditions.items():\n",
    "        for col, max_value in max_values.items():\n",
    "            df = df[~((df['day_part_x'] == day_part) & (df[col] > max_value))]\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Filter the DataFrame\n",
    "clean_data = day_part_no_check(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Action can only take 0, 1, 2, same applies to day_part_x.\n",
    "\n",
    "def check_action_daypart(df):\n",
    "    # Define conditions\n",
    "    condition_action = df['action'].isin([0, 1, 2])\n",
    "    condition_day_part_x = df['day_part_x'].isin([0, 1, 2])\n",
    "    \n",
    "    # Filter DataFrame based on conditions\n",
    "    df_filtered = df[condition_action & condition_day_part_x]\n",
    "    \n",
    "    return df_filtered\n",
    "\n",
    "# Call the function\n",
    "clean_data = check_action_daypart(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.dirname(\"data/clean_data.csv\"), exist_ok=True)\n",
    "clean_data.to_csv(\"data/clean_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GReaT(llm='distilgpt2', \n",
    "              batch_size=32,  \n",
    "              epochs=1, \n",
    "              logging_steps=100)\n",
    "\n",
    "model.fit(clean_data)\n",
    "\n",
    "synthetic_data = model.sample(len(clean_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Save synthetic data to CSV file\n",
    "os.makedirs(os.path.dirname(\"data/great_data.csv\"), exist_ok=True)\n",
    "synthetic_data.to_csv(\"data/great_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
